---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}
data = read.table(file.choose(),header = TRUE,sep = '\t',dec = '.' )
data_mat = data.matrix(data)

```
```{r}
head(data_mat)
```
```{r}
library(kernlab)
svm_model = ksvm(data_mat[,1:10],data[,11],type = "C-svc",kernel = 'vanilladot',C=100,scaled=TRUE)
```
find ai-s
```{r}
a = colSums(svm_model@xmatrix[[1]]*svm_model@coef[[1]])
a0 = svm_model@b
```
test prediction
```{r}
pred = predict(svm_model,data_mat[,1:10])
sum(pred==data_mat[,11])/nrow(data_mat)
```
```{r}
library(kknn)
knn_model = train.kknn(R1 ~ .,data,kmax = 10,scale=TRUE )
knn_pred = predict(knn_model,data[,-11])
knn_pred[knn_pred>0.5] = 1
knn_pred[knn_pred<=0.5] = 0
sum(knn_pred==data[,11])/nrow(data)
```
```{r}
# cross-validation
library(caret)
# split data
smp_size <- floor(0.2 * nrow(data))
set.seed(12345)
test_ind = sample(seq_len(nrow(data)), size = smp_size)
train_validation = data[-test_ind,]
test = data[test_ind,]
# list of indeces
folds <- createFolds(train_validation[,'R1'], k = 10, list = TRUE, returnTrain = FALSE)
acurracies = array(1:10)
for (i in 1:10){
  validation = train_validation[folds[[i]],]
  train = train_validation[-folds[[i]],]
  knn_model = train.kknn(R1 ~ .,train,kmax = 3,scale=TRUE )
  knn_pred = predict(knn_model,validation[,-11])
  knn_pred[knn_pred>0.5] = 1
  knn_pred[knn_pred<=0.5] = 0
  acurracies[i] = sum(knn_pred==validation[,11])/nrow(data)
}
print(sum(acurracies)/10)

#train on the whole train-validation set
knn_model = train.kknn(R1 ~ .,train_validation,kmax = 10,scale=TRUE )
knn_pred = predict(knn_model,test[,-11])
knn_pred[knn_pred>0.5] = 1
knn_pred[knn_pred<=0.5] = 0
acurracy_test = sum(knn_pred==test[,11])/nrow(data)
```

